{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Conceptual Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. What is the difference between train and test set? -   Train set is used to build the model \n",
    "#while the Test set is used to test the model, i.e.: to evaluate the model's accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. Why is it important to have a seperate data set for training? - \n",
    "#Using similar data for training and testing, you can minimize the effects of data discrepancies and better understand the characteristics of the model.  \n",
    "#After a model has been processed by using the training set, you test the model by making predictions against the test set. Because the data in the testing set already contains known values for the attribute that you want to predict, it is easy to determine whether the model's guesses are correct rather than just seeing if the model has memorized the data which it would if it had not been separated initially. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. What are some advantages and disadvantages of the KNN algorithm? - \n",
    "#The main disadvantage of this approach is that the algorithm must compute the distance and sort all the training data at each prediction, which can be slow if there are a large number of training examples. \n",
    "#Another disadvantage of this approach is that the algorithm does not learn anything from the training data, which can result in the algorithm not generalizing well and also not being robust to noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. Explain in your own words the bias variance tradeoff. - The “tradeoff” between bias and variance can be viewed in this manner – a model with low bias must be flexible so that it can fit the data well. But if the model is too flexible it will fit each training data set differently (high variance). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Do you think KNN suffers from high bias or high variance? KNN has low bias (doesn’t really assume anything about the distribution of the data points) but high variance, because it can easily change its prediction in response to the composition of the training set. KNN can fit the training data very well if K is chosen small enough (in the extreme case with K=1 the fit will be perfect) but may not generalize well to new examples; high variance is related to over-fitting.#5. Do you think KNN suffers from high bias or high variance? -   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6. List some possible solutions when suffering from high variance. - More training examples & fewer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7. List some possible solutions when suffereing from high bias - Additional features & the addition of polynomial and interaction features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8. Would you choose K when doing K Nearest Neighbors?  -Use k-fold for cross validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Practical\n",
    "\n",
    "### Data set description - In this section you will be analysis a data set from (Stamey et al., 1989) on the analysis of prostate cancer. \n",
    "#There are 97 obvservations and 8 features corresponding to various clinical measurements.\n",
    "#* lcavol: log(cancer volume) \n",
    "#* lweight: log(prostate weight) \n",
    "#* age\n",
    "#* lbph: logarithm of the amount of benign prostatic hyperplasia\n",
    "#* svi: seminal vesicle invasion\n",
    "#* lcp: log(capsular penetration) \n",
    "#* gleason: Gleason score \n",
    "#* pgg45: percentage Gleason score 4 or 5\n",
    "\n",
    "#You will be builing a regressor on the above features to try and predict the logarithm of prostate-specific antigen (lpsa)\n",
    "\n",
    "\n",
    "#The data has already been split into a training and test set in the original study. \n",
    "#The column train indicates if the example is part of the training or test set. \n",
    "#A T in the column train means that observation is a training set and an F in the column indicates it's a test set. \n",
    "\n",
    "#Stamey, T., Kabalin, J., McNeal, J., Johnstone, I., Freiha, F., Redwine, E. and Yang, N. (1989) Prostate specific\n",
    "#antigen in the diagnosis and treatment of adenocarcinoma of the prostate ii: radical prostatectomy treated\n",
    "#patients. J. Urol., 16, 1076–1083."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import grid_search\n",
    "from sklearn import cross_validation\n",
    "import statsmodels.formula.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PC=pd.read_csv('https://raw.githubusercontent.com/galvin-mj/DAT_ATL_15/master/Datasets/ProstateCancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del PC['Unnamed: 0']\n",
    "PC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6     False\n",
       "7      True\n",
       "8     False\n",
       "9     False\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14    False\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21    False\n",
       "22     True\n",
       "23     True\n",
       "24    False\n",
       "25    False\n",
       "26     True\n",
       "27    False\n",
       "28     True\n",
       "29     True\n",
       "      ...  \n",
       "67     True\n",
       "68     True\n",
       "69     True\n",
       "70     True\n",
       "71     True\n",
       "72    False\n",
       "73    False\n",
       "74     True\n",
       "75     True\n",
       "76     True\n",
       "77     True\n",
       "78     True\n",
       "79    False\n",
       "80     True\n",
       "81     True\n",
       "82     True\n",
       "83    False\n",
       "84     True\n",
       "85     True\n",
       "86     True\n",
       "87     True\n",
       "88     True\n",
       "89     True\n",
       "90     True\n",
       "91     True\n",
       "92     True\n",
       "93     True\n",
       "94    False\n",
       "95     True\n",
       "96    False\n",
       "Name: train, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC['train'] == 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = PC[PC['train'] == 'T'].drop('train', 1).drop('lpsa', 1)\n",
    "scaled_train_x = sk.preprocessing.scale(train_x)\n",
    "train_y = PC['lpsa'][PC['train'] == 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x = PC[PC['train'] == 'F'].drop('train', 1).drop('lpsa', 1)\n",
    "scaled_test_x = sk.preprocessing.scale(test_x)\n",
    "test_y = PC['lpsa'][PC['train'] == 'F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient [ 0.71104059  0.29045029 -0.14148182  0.21041951  0.30730025 -0.28684075\n",
      " -0.02075686  0.27526843]\n",
      "intercept 2.45234508507\n",
      "Mean squared error for liner regression: 0.5521606838\n"
     ]
    }
   ],
   "source": [
    "lr_rgr = linear_model.LinearRegression()\n",
    "lr_rgr.fit(scaled_train_x,train_y)\n",
    "print(\"coefficient {}\".format(lr_rgr.coef_))\n",
    "print(\"intercept {}\".format(lr_rgr.intercept_))\n",
    "\n",
    "LR_MSE = mean_squared_error(test_y, lr_rgr.predict(scaled_test_x))\n",
    "print('Mean squared error for liner regression: {}'.format(LR_MSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear Mean Squared Error is', 0.55216068380027317)\n",
      "Linear Regression Model Coefficients Are:\n",
      "[(0.71104059225617944, 'lcavol'), (0.29045029198643257, 'lweight'), (-0.14148182348942548, 'age'), (0.21041951018479577, 'lbph'), (0.30730025297185726, 'svi'), (-0.28684074913663932, 'lcp'), (-0.020756862036926227, 'gleason'), (0.27526842547776681, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "sk_linreg_model = sk.linear_model.LinearRegression()\n",
    "sk_linreg_model.fit(scaled_train_x,train_y.values)\n",
    "linreg_error = mean_squared_error(test_y,sk_linreg_model.predict(scaled_test_x))\n",
    "print('Linear Mean Squared Error is',linreg_error)\n",
    "print 'Linear Regression Model Coefficients Are:'\n",
    "print([i for i in zip(sk_linreg_model.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('StatsModels Linear Regression Mean Squared Error is', 0.52127400550759451)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   lpsa   R-squared:                       0.694\n",
      "Model:                            OLS   Adj. R-squared:                  0.652\n",
      "Method:                 Least Squares   F-statistic:                     16.47\n",
      "Date:                Thu, 08 Oct 2015   Prob (F-statistic):           2.04e-12\n",
      "Time:                        16:39:42   Log-Likelihood:                -67.505\n",
      "No. Observations:                  67   AIC:                             153.0\n",
      "Df Residuals:                      58   BIC:                             172.9\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.4292      1.554      0.276      0.783        -2.681     3.539\n",
      "lcavol         0.5765      0.107      5.366      0.000         0.361     0.792\n",
      "lweight        0.6140      0.223      2.751      0.008         0.167     1.061\n",
      "age           -0.0190      0.014     -1.396      0.168        -0.046     0.008\n",
      "lbph           0.1448      0.070      2.056      0.044         0.004     0.286\n",
      "svi            0.7372      0.299      2.469      0.017         0.140     1.335\n",
      "lcp           -0.2063      0.111     -1.867      0.067        -0.428     0.015\n",
      "gleason       -0.0295      0.201     -0.147      0.884        -0.432     0.373\n",
      "pgg45          0.0095      0.005      1.738      0.088        -0.001     0.020\n",
      "==============================================================================\n",
      "Omnibus:                        0.825   Durbin-Watson:                   1.690\n",
      "Prob(Omnibus):                  0.662   Jarque-Bera (JB):                0.389\n",
      "Skew:                          -0.164   Prob(JB):                        0.823\n",
      "Kurtosis:                       3.178   Cond. No.                     1.29e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.29e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'lcavol':train_x['lcavol'].values,'lweight':train_x['lweight'].values,'age':train_x['age'].values,'lbph':train_x['lbph'].values,'svi':train_x['svi'].values,'lcp':train_x['lcp'].values,'gleason':train_x['gleason'].values,'pgg45':train_x['pgg45'].values,'lpsa':train_y.values})\n",
    "linrgr = sm.ols(formula='lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + pgg45', data = df)\n",
    "linreg_model = linrgr.fit()\n",
    "linreg_error = mean_squared_error(test_y,linreg_model.predict(test_x))\n",
    "print('StatsModels Linear Regression Mean Squared Error is',linreg_error)\n",
    "print(linreg_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN Mean Squared Error is', 0.59926712073161914)\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsRegressor(n_neighbors = 25)\n",
    "knn_error = mean_squared_error(knn.fit(scaled_train_x, train_y).predict(scaled_test_x),test_y.values)\n",
    "print('KNN Mean Squared Error is',knn_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN Mean Squared Error is', 0.59926712073161914)\n",
      "('Best n_neighbors is', 25)\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'n_neighbors': range(1,50)}]\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "knn_cv = grid_search.GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_cv.fit(scaled_train_x, train_y.values)\n",
    "\n",
    "knn_error = mean_squared_error(knn_cv.predict(scaled_test_x),test_y.values)\n",
    "print('KNN Mean Squared Error is',knn_error)\n",
    "print('Best n_neighbors is',knn_cv.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lasso Mean Squared Error is', 0.46548012858101179)\n",
      "('Best alpha is', 0.24489795925918367)\n",
      "Lasso Regression Model Coefficients Are:\n",
      "[(0.54344880315864541, 'lcavol'), (0.16068697908521809, 'lweight'), (0.0, 'age'), (0.0, 'lbph'), (0.071347172585480803, 'svi'), (0.0, 'lcp'), (0.0, 'gleason'), (0.0, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 1, 50)}]\n",
    "\n",
    "lasso_rgr = Lasso()\n",
    "lasso_cv = grid_search.GridSearchCV(lasso_rgr, param_grid, cv=5)\n",
    "lasso_cv.fit(scaled_train_x, train_y.values)\n",
    "lasso_error = mean_squared_error(lasso_cv.predict(scaled_test_x),test_y.values)\n",
    "\n",
    "print('Lasso Mean Squared Error is',lasso_error)\n",
    "print('Best alpha is',lasso_cv.best_params_['alpha'])\n",
    "print('Lasso Regression Model Coefficients Are:')\n",
    "print([i for i in zip(lasso_cv.best_estimator_.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ridge Mean Squared Error is', 0.54265110682660178)\n",
      "('Best alpha is', 1.0)\n",
      "Ridge Regression Model Coefficients Are:\n",
      "[(0.68540968559009774, 'lcavol'), (0.28959545148607768, 'lweight'), (-0.13430643457339905, 'age'), (0.20841056512642403, 'lbph'), (0.30162493925781103, 'svi'), (-0.25453234425183563, 'lcp'), (-0.011251696970697243, 'gleason'), (0.25598543189236278, 'pgg45')]\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'alpha': np.linspace(1e-10, 1, 50)}]\n",
    "\n",
    "ridge_rgr = Ridge()\n",
    "ridge_cv = grid_search.GridSearchCV(ridge_rgr, param_grid, cv=5)\n",
    "ridge_cv.fit(scaled_train_x, train_y.values)\n",
    "ridge_error = mean_squared_error(ridge_cv.predict(scaled_test_x),test_y.values)\n",
    "\n",
    "print('Ridge Mean Squared Error is',ridge_error)\n",
    "print('Best alpha is',ridge_cv.best_params_['alpha'])\n",
    "print('Ridge Regression Model Coefficients Are:')\n",
    "print([i for i in zip(ridge_cv.best_estimator_.coef_,train_x.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Perform regression on the prostate data set. Your goal is to minimize the mean squared error (MSE).\n",
    "#Split this into a several parts and at a minimum utilize Linear Regression, KNN, Lasso, Ridge, \n",
    "#Use cross validation to tune the best model you can.  \n",
    "#See models above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. Where there any features that were highly correlated? - age, lbph pgg45 and gleason.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. What features were the most important? Unimportant? - lcavol, weight and svi are important.\n",
    "#age, lpbh & gleason are not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. What model worked best? What was the MSE of each?\n",
    "#Lasso worked the best with a MSE of 0.465.  Linear Reg, KNN and Ridge has 0.55, 0.59 and 0.54 respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. What difficulties did you have with this data set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
